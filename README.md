# Data_Wrangling
Data wrangling process:

- Gather
- Assess
- Clean

Data wrangling is the process of gathering data, assessing its quality and structure, and cleaning it before doing things like analysis, visualization, or build predictive models using machine learning.

In this repository, I will gather, assess and clean the "Phase II clinical trial data" that compares the efficacy and safety of a new oral insulin to treat diabetes.

Here, i am using three csv files as my input namely :

1. patients.csv
2. treatments.csv
3. adverse_reactions.csv

For this project I have used python in jupyter notebooks to systematically clean the dataset. You can learn basics about jupyter notebook here - https://www.youtube.com/watch?v=IMrxB8Mq5KU

All csv files and jupyter notebooks are in this repository.Here is the [Code]()
